{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_06 - Using DSPY to optimize our prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0] Setting Up\n",
    "\n",
    "DSPY is a framework for letting you optimize prompts by defining programs. Rather than focusing on the prompt, you focus on the system and let an optimizer optimize prompts for you.\n",
    "\n",
    "Inspired and samples from the intro DSPY notebook https://github.com/stanfordnlp/dspy/blob/main/intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (24.1.2)\n",
      "Requirement already satisfied: dspy-ai in ./.venv/lib/python3.10/site-packages (2.4.12)\n",
      "Requirement already satisfied: openai~=0.28.1 in ./.venv/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: backoff in ./.venv/lib/python3.10/site-packages (from dspy-ai) (2.2.1)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.10/site-packages (from dspy-ai) (2.20.0)\n",
      "Requirement already satisfied: joblib<=1.3.2 in ./.venv/lib/python3.10/site-packages (from dspy-ai) (1.3.2)\n",
      "Requirement already satisfied: optuna in ./.venv/lib/python3.10/site-packages (from dspy-ai) (3.6.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from dspy-ai) (2.2.2)\n",
      "Requirement already satisfied: pydantic~=2.0 in ./.venv/lib/python3.10/site-packages (from dspy-ai) (2.8.2)\n",
      "Requirement already satisfied: regex in ./.venv/lib/python3.10/site-packages (from dspy-ai) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from dspy-ai) (2.32.3)\n",
      "Requirement already satisfied: structlog in ./.venv/lib/python3.10/site-packages (from dspy-ai) (24.4.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from dspy-ai) (4.66.4)\n",
      "Requirement already satisfied: ujson in ./.venv/lib/python3.10/site-packages (from dspy-ai) (5.10.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from openai~=0.28.1) (3.9.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic~=2.0->dspy-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic~=2.0->dspy-ai) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.10/site-packages (from pydantic~=2.0->dspy-ai) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->dspy-ai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->dspy-ai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->dspy-ai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->dspy-ai) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai~=0.28.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai~=0.28.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai~=0.28.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai~=0.28.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai~=0.28.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->openai~=0.28.1) (4.0.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in ./.venv/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->dspy-ai) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (0.23.5)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets->dspy-ai) (6.0.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.venv/lib/python3.10/site-packages (from optuna->dspy-ai) (1.13.2)\n",
      "Requirement already satisfied: colorlog in ./.venv/lib/python3.10/site-packages (from optuna->dspy-ai) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.venv/lib/python3.10/site-packages (from optuna->dspy-ai) (2.0.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->dspy-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->dspy-ai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->dspy-ai) (2024.1)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->dspy-ai) (1.3.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->dspy-ai) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->dspy-ai) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna->dspy-ai) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/grounding-techniques-for-llms-3896093/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pip dspy-ai openai~=0.28.1\n",
    "import dspy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_model_name = \"gpt-4o-mini\"\n",
    "prompt_model = dspy.OpenAI(model=prompt_model_name, max_tokens=1000, stop=[\"\\n\\n\", \"\\n---\"])\n",
    "task_model = dspy.OpenAI(model=prompt_model_name, max_tokens=1000, stop=[\"\\n\\n\", \"\\n---\", \"assistant\"])\n",
    "dspy.settings.configure(lm=task_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1] Basic Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the HotpotQA dataset to get us started. It's a collection of abstracts (first paragraphs) from wikipedia https://hotpotqa.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "\n",
    "# parse the training set and dev set\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "len(trainset), len(devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loaded a training dataset called `trainset` (20 examples) and our validation set `devset` (50 examples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n"
     ]
    }
   ],
   "source": [
    "train_example = trainset[0]\n",
    "print(f\"Question: {train_example.question}\")\n",
    "print(f\"Answer: {train_example.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2] DSPY Building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Programs, Signatures & Predictors\n",
    "\n",
    "Program - LLM task you want to accomplish\n",
    "\n",
    "Signature - Input and output guidance for a program\n",
    "\n",
    "Predictor - A way to run a program and generate a result\n",
    "\n",
    "Each program needs at least one signature.\n",
    "\n",
    "A signature consists of three simple elements:\n",
    "\n",
    "- A minimal description of the sub-task the LM is supposed to solve.\n",
    "- A description of one or more input fields (e.g., input question) that we will give to the LM.\n",
    "- A description of one or more output fields (e.g., the question's answer) that we will expect from the LM.\n",
    "\n",
    "Let's define a simple signature for basic question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Predicted Answer: American\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "dev_example = devset[18]\n",
    "# predict the answer using the signature\n",
    "pred = generate_answer(question=dev_example.question)\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's inspect the history of our LM (**gpt4omini**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Answer:\u001b[32m American\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAnswer questions with short factoid answers.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nAnswer:\\x1b[32m American\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a chain of thought predictor and see how the responses change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Thought: The chef featured in Restaurant: Impossible is Robert Irvine, who is from the United Kingdom.\n",
      "Predicted Answer: British\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
    "generate_answer_with_chain_of_thought = dspy.ChainOfThought(BasicQA)\n",
    "\n",
    "# Call the predictor on the same input.\n",
    "pred = generate_answer_with_chain_of_thought(question=dev_example.question)\n",
    "\n",
    "# Print the input, the chain of thought, and the prediction.\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is indeed a better answer: the model figures out that the chef in question is **Robert Irvine** and correctly identifies that he's British.\n",
    "\n",
    "These predictors (`dspy.Predict` and `dspy.ChainOfThought`) can be applied to _any_ signature. As we'll see below, they can also be optimized to learn from your data and validation logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3] Defining metrics and evaluator\n",
    "\n",
    "Now that we have a basic predictor set up let's make it more systematic by defining an exact metric and running through an evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate = Evaluate(devset=devset, metric=metric)\n",
    "\n",
    "baseline_train_score = evaluate(generate_answer,devset=trainset)\n",
    "baseline_dev_score = evaluate(generate_answer, devset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train score: 30.0\n",
      "Baseline dev score: 22.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline train score:\", baseline_train_score)\n",
    "print(\"Baseline dev score:\", baseline_dev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4] Compiling a program with a teleprompter\n",
    "\n",
    "So far we've just used a regular prompt to get an answer, let's have DSPY try to optimize our prompts. We'll need to define a search technique called a **teleprompter** and a teacher model to construct the demontrations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 5 traces per predictor.\n",
      "Will attempt to bootstrap 5 candidate sets.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# we'll generate an number of programs in parralel when compiling using gpt4omini as an evaluator\n",
    "bootstrap_optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    max_bootstrapped_demos=5,\n",
    "    max_labeled_demos=5,\n",
    "    num_candidate_programs=5,\n",
    "    num_threads=8,\n",
    "    metric=metric,\n",
    "    teacher_settings=dict(lm=prompt_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 8  (50.0):  14%|█▍        | 7/50 [00:00<00:00, 338.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 50  (34.0): 100%|██████████| 50/50 [00:00<00:00, 756.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 34.0 for set: [0]\n",
      "New best sscore: 34.0 for seed -3\n",
      "Scores so far: [34.0]\n",
      "Best score: 34.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:00<00:00, 576.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.0 for set: [5]\n",
      "New best sscore: 38.0 for seed -2\n",
      "Scores so far: [34.0, 38.0]\n",
      "Best score: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:00<00:00, 864.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 14 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 50  (40.0): 100%|██████████| 50/50 [00:00<00:00, 560.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 40.0 for set: [5]\n",
      "New best sscore: 40.0 for seed -1\n",
      "Scores so far: [34.0, 38.0, 40.0]\n",
      "Best score: 40.0\n",
      "Average of max per entry across top 1 scores: 0.4\n",
      "Average of max per entry across top 2 scores: 0.42\n",
      "Average of max per entry across top 3 scores: 0.44\n",
      "Average of max per entry across top 5 scores: 0.44\n",
      "Average of max per entry across top 8 scores: 0.44\n",
      "Average of max per entry across top 9999 scores: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:00<00:00, 1126.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:00<00:00, 584.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.0 for set: [5]\n",
      "Scores so far: [34.0, 38.0, 40.0, 38.0]\n",
      "Best score: 40.0\n",
      "Average of max per entry across top 1 scores: 0.4\n",
      "Average of max per entry across top 2 scores: 0.42\n",
      "Average of max per entry across top 3 scores: 0.42\n",
      "Average of max per entry across top 5 scores: 0.44\n",
      "Average of max per entry across top 8 scores: 0.44\n",
      "Average of max per entry across top 9999 scores: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:00<00:00, 955.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:00<00:00, 548.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.0 for set: [5]\n",
      "Scores so far: [34.0, 38.0, 40.0, 38.0, 38.0]\n",
      "Best score: 40.0\n",
      "Average of max per entry across top 1 scores: 0.4\n",
      "Average of max per entry across top 2 scores: 0.42\n",
      "Average of max per entry across top 3 scores: 0.42\n",
      "Average of max per entry across top 5 scores: 0.44\n",
      "Average of max per entry across top 8 scores: 0.44\n",
      "Average of max per entry across top 9999 scores: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:00, 743.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:00<00:00, 604.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 32.0 for set: [5]\n",
      "Scores so far: [34.0, 38.0, 40.0, 38.0, 38.0, 32.0]\n",
      "Best score: 40.0\n",
      "Average of max per entry across top 1 scores: 0.4\n",
      "Average of max per entry across top 2 scores: 0.42\n",
      "Average of max per entry across top 3 scores: 0.42\n",
      "Average of max per entry across top 5 scores: 0.44\n",
      "Average of max per entry across top 8 scores: 0.44\n",
      "Average of max per entry across top 9999 scores: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:00<00:00, 867.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:00<00:00, 540.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.0 for set: [5]\n",
      "Scores so far: [34.0, 38.0, 40.0, 38.0, 38.0, 32.0, 38.0]\n",
      "Best score: 40.0\n",
      "Average of max per entry across top 1 scores: 0.4\n",
      "Average of max per entry across top 2 scores: 0.42\n",
      "Average of max per entry across top 3 scores: 0.42\n",
      "Average of max per entry across top 5 scores: 0.42\n",
      "Average of max per entry across top 8 scores: 0.44\n",
      "Average of max per entry across top 9999 scores: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:00<00:00, 781.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:00<00:00, 599.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.0 for set: [5]\n",
      "Scores so far: [34.0, 38.0, 40.0, 38.0, 38.0, 32.0, 38.0, 38.0]\n",
      "Best score: 40.0\n",
      "Average of max per entry across top 1 scores: 0.4\n",
      "Average of max per entry across top 2 scores: 0.42\n",
      "Average of max per entry across top 3 scores: 0.42\n",
      "Average of max per entry across top 5 scores: 0.42\n",
      "Average of max per entry across top 8 scores: 0.44\n",
      "Average of max per entry across top 9999 scores: 0.44\n",
      "8 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cot_fewshot = bootstrap_optimizer.compile(generate_answer_with_chain_of_thought, trainset=trainset, valset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1914, while Anatoly Fomenko was born in 1932. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "---\n",
      "\n",
      "Question: \"Everything Has Changed\" is a song from an album released under which record label ?\n",
      "Reasoning: Let's think step by step in order to identify the record label associated with the song \"Everything Has Changed.\" We need to consider the artist and the album's release details. The song is by Taylor Swift featuring Ed Sheeran, from the album \"Red,\" which was released under Big Machine Records.\n",
      "Answer: Big Machine Records\n",
      "\n",
      "---\n",
      "\n",
      "Question: Tombstone stared an actor born May 17, 1955 known as who?\n",
      "Answer: Bill Paxton\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Answer: The Empire State Building\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Gordon Warnecke worked alongside the former senator for which political party on Young Toscanini?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the political affiliation of the former senator Gordon Warnecke worked with on Young Toscanini. The former senator is likely to be associated with the Democratic Party, as he was known for his work in that political context.\n",
      "Answer: Democratic Party\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAnswer questions with short factoid answers.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nReasoning: Let\\'s think step by step in order to ${produce the answer}. We ...\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nQuestion: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\\nReasoning: Let\\'s think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1914, while Anatoly Fomenko was born in 1932. Therefore, Aleksandr Danilovich Aleksandrov is older.\\nAnswer: Aleksandr Danilovich Aleksandrov\\n\\n---\\n\\nQuestion: \"Everything Has Changed\" is a song from an album released under which record label ?\\nReasoning: Let\\'s think step by step in order to identify the record label associated with the song \"Everything Has Changed.\" We need to consider the artist and the album\\'s release details. The song is by Taylor Swift featuring Ed Sheeran, from the album \"Red,\" which was released under Big Machine Records.\\nAnswer: Big Machine Records\\n\\n---\\n\\nQuestion: Tombstone stared an actor born May 17, 1955 known as who?\\nAnswer: Bill Paxton\\n\\n---\\n\\nQuestion: Which is taller, the Empire State Building or the Bank of America Tower?\\nAnswer: The Empire State Building\\n\\n---\\n\\nQuestion: At My Window was released by which American singer-songwriter?\\nAnswer: John Townes Van Zandt\\n\\n---\\n\\nQuestion: Gordon Warnecke worked alongside the former senator for which political party on Young Toscanini?\\nReasoning: Let\\'s think step by step in order to\\x1b[32m determine the political affiliation of the former senator Gordon Warnecke worked with on Young Toscanini. The former senator is likely to be associated with the Democratic Party, as he was known for his work in that political context.\\nAnswer: Democratic Party\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0\n"
     ]
    }
   ],
   "source": [
    "compiled_dev_score = evaluate(cot_fewshot, devset=devset)\n",
    "print(compiled_dev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4] Trying a different optimizer - MIPRO\n",
    "Similar to different optmizers in model training like SGD, AdamW and Sophia, DSPY has a similar suite, Let's try compiling with Mipro to see if we get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "mipro_teleprompter = MIPROv2(prompt_model=prompt_model, task_model=task_model, metric=metric, num_candidates=5, init_temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWARNING: Projected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Please be advised that based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\n",
      "\u001b[93m- Prompt Model: \u001b[94m\u001b[1m10\u001b[0m\u001b[93m data summarizer calls + \u001b[94m\u001b[1m5\u001b[0m\u001b[93m * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m lm calls in program + (\u001b[94m\u001b[1m2\u001b[0m\u001b[93m) lm calls in program aware proposer = \u001b[94m\u001b[1m17\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\u001b[93m- Task Model: \u001b[94m\u001b[1m25\u001b[0m\u001b[93m examples in minibatch * \u001b[94m\u001b[1m10\u001b[0m\u001b[93m batches + \u001b[94m\u001b[1m20\u001b[0m\u001b[93m examples in train set * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m full evals = \u001b[94m\u001b[1m270\u001b[0m\u001b[93m task model calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of calls to prompt model * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_batches`), the size of the trainset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting source code: could not find class definition.\n",
      "\n",
      "Running without program aware proposer.\n",
      "b: 10\n",
      "summary: Prediction(\n",
      "    summary='Observations: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.'\n",
      ")\n",
      "DATA SUMMARY: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:00, 631.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:00, 690.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:00, 702.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.\n",
      "\n",
      "TASK DEMO(S): \n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001b[32m Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.\n",
      "\n",
      "TASK DEMO(S): \n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001b[32m Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/grounding-techniques-for-llms-3896093/.venv/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2024-07-21 19:14:03,819] A new study created in memory with name: no-name-36dad537-7db2-44c9-bd5f-97862548ee62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_demos Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine the publication dates of both titles. We need to check the release years of \"Who Put the Bomp\" and \"Self\" to see which one is more recent.\n",
      "Answer: Self\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.\n",
      "\n",
      "TASK DEMO(S):\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine the publication dates of both titles. We need to check the release years of \"Who Put the Bomp\" and \"Self\" to see which one is more recent.\n",
      "Answer: Self\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001b[32m Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "task_demos Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.\n",
      "\n",
      "TASK DEMO(S):\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001b[32m Propose a detailed instruction that prompts the Language Model to analyze and reason through trivia questions by first identifying the key figures and events involved, then providing the necessary information to derive an accurate answer, while emphasizing the importance of comparing relevant facts to reach a conclusion.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose a detailed instruction that prompts the Language Model to analyze and reason through trivia questions by first identifying the key figures and events involved, then providing the necessary information to derive an accurate answer, while emphasizing the importance of comparing relevant facts to reach a conclusion.\n",
      "task_demos Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Reasoning: Let's think step by step in order to compare their heights. The Empire State Building is 1,454 feet tall, while the Bank of America Tower is 1,200 feet tall. Therefore, the Empire State Building is taller.\n",
      "Answer: Empire State Building\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset includes various trivia questions related to musicians, actors, historical events, and publications, with a strong focus on American culture and notable figures. Key examples highlight the release of songs, film debuts, and sports history, alongside factual data about organizations and geographical locations.\n",
      "\n",
      "TASK DEMO(S):\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Reasoning: Let's think step by step in order to compare their heights. The Empire State Building is 1,454 feet tall, while the Bank of America Tower is 1,200 feet tall. Therefore, the Empire State Building is taller.\n",
      "Answer: Empire State Building\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001b[32m Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n",
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine which publication has a later release date. \"Who Put the Bomp\" was published in 2003, while \"Self\" was published in 2018. Therefore, \"Self\" is the more recent publication.\n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Provide concise and factual answers to the following trivia questions about musicians, actors, historical events, and American cultural figures, ensuring you highlight key details such as dates, notable achievements, and relevant contexts.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine which publication has a later release date. \"Who Put the Bomp\" was published in 2003, while \"Self\" was published in 2018. Therefore, \"Self\" is the more recent publication.\n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 45.0\n",
      "Best Combination: 1,{0: [[], [Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'}), Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys={'question'})], [Example({'augmented': True, 'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'rationale': 'determine the publication dates of both titles. We need to check the release years of \"Who Put the Bomp\" and \"Self\" to see which one is more recent.', 'answer': 'Self'}) (input_keys=None), Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys={'question'})], [Example({'augmented': True, 'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'rationale': 'determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None), Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys={'question'})], [Example({'augmented': True, 'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'rationale': 'compare their heights. The Empire State Building is 1,454 feet tall, while the Bank of America Tower is 1,200 feet tall. Therefore, the Empire State Building is taller.', 'answer': 'Empire State Building'}) (input_keys=None), Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys={'question'})]]} with Mean = 45.0\n",
      "UPDATING BEST SCORE WITH 45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:15:05,898] Trial 0 finished with value: 45.0 and parameters: {'0_predictor_instruction': 1, '0_predictor_demos': 1}. Best is trial 0 with value: 45.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:15:31,196] Trial 1 finished with value: 35.0 and parameters: {'0_predictor_instruction': 2, '0_predictor_demos': 1}. Best is trial 0 with value: 45.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of both magazines. \"Who Put the Bomp\" was first published in 2003, while \"Self\" magazine has been in circulation since 1976 and continues to be published. Therefore, \"Who Put the Bomp\" is the more recent publication.  \n",
      "Answer: Who Put the Bomp\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of both magazines. \"Who Put the Bomp\" was first published in 2003, while \"Self\" magazine has been in circulation since 1976 and continues to be published. Therefore, \"Who Put the Bomp\" is the more recent publication.  \n",
      "Answer: Who Put the Bomp\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 35.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:16:17,129] Trial 2 finished with value: 30.0 and parameters: {'0_predictor_instruction': 4, '0_predictor_demos': 1}. Best is trial 0 with value: 45.0.\n",
      "[I 2024-07-21 19:16:17,141] Trial 3 finished with value: 35.0 and parameters: {'0_predictor_instruction': 2, '0_predictor_demos': 1}. Best is trial 0 with value: 45.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine which publication was released last. We need to find the release dates of both \"Who Put the Bomp\" and \"Self.\" \"Who Put the Bomp\" was published in 1996, while \"Self\" was published in 2000. Since 2000 is later than 1996, \"Self\" is the most recently published.\n",
      "Answer:\u001b[32m Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine which publication was released last. We need to find the release dates of both \"Who Put the Bomp\" and \"Self.\" \"Who Put the Bomp\" was published in 1996, while \"Self\" was published in 2000. Since 2000 is later than 1996, \"Self\" is the most recently published.\n",
      "Answer:\u001b[32m Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 30.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n",
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of both magazines. \"Who Put the Bomp\" was first published in 2003, while \"Self\" magazine has been in circulation since 1976 and continues to be published. Therefore, \"Who Put the Bomp\" is the more recent publication.  \n",
      "Answer: Who Put the Bomp\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer trivia questions by providing a concise fact-based response. When applicable, include a brief reasoning process that outlines how you arrived at the answer, especially when comparing items or dates. Use clear examples and relevant context related to American culture, musicians, actors, historical events, and publications to reinforce your answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of both magazines. \"Who Put the Bomp\" was first published in 2003, while \"Self\" magazine has been in circulation since 1976 and continues to be published. Therefore, \"Who Put the Bomp\" is the more recent publication.  \n",
      "Answer: Who Put the Bomp\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 35.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:16:43,882] Trial 4 finished with value: 40.0 and parameters: {'0_predictor_instruction': 4, '0_predictor_demos': 3}. Best is trial 0 with value: 45.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the publication years of each work. \"Who Put the Bomp\" was published in 1990, while \"Self\" was published in 1991. Therefore, \"Self\" is the more recent publication.\n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the publication years of each work. \"Who Put the Bomp\" was published in 1990, while \"Self\" was published in 1991. Therefore, \"Self\" is the more recent publication.\n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 40.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Answer questions with short factoid answers.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:17:04,469] Trial 5 finished with value: 50.0 and parameters: {'0_predictor_instruction': 0, '0_predictor_demos': 1}. Best is trial 5 with value: 50.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the publication dates of both titles. We need to check the release years of \"Who Put the Bomp\" and \"Self\" to see which one is more recent. \n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the publication dates of both titles. We need to check the release years of \"Who Put the Bomp\" and \"Self\" to see which one is more recent. \n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 50.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:17:32,595] Trial 6 finished with value: 35.0 and parameters: {'0_predictor_instruction': 4, '0_predictor_demos': 4}. Best is trial 5 with value: 50.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Reasoning: Let's think step by step in order to compare their heights. The Empire State Building is 1,454 feet tall, while the Bank of America Tower is 1,200 feet tall. Therefore, the Empire State Building is taller.\n",
      "Answer: Empire State Building\n",
      "\n",
      "---\n",
      "\n",
      "Question: This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?\n",
      "Answer: The Waltz King\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of each magazine. \"Who Put the Bomp\" was first published in 1993, while \"Self\" magazine was first published in 1976. Since \"Who Put the Bomp\" was published later than \"Self,\" it is the most recently published publication.\n",
      "Answer: Who Put the Bomp\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Reasoning: Let's think step by step in order to compare their heights. The Empire State Building is 1,454 feet tall, while the Bank of America Tower is 1,200 feet tall. Therefore, the Empire State Building is taller.\n",
      "Answer: Empire State Building\n",
      "\n",
      "---\n",
      "\n",
      "Question: This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?\n",
      "Answer: The Waltz King\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of each magazine. \"Who Put the Bomp\" was first published in 1993, while \"Self\" magazine was first published in 1976. Since \"Who Put the Bomp\" was published later than \"Self,\" it is the most recently published publication.\n",
      "Answer: Who Put the Bomp\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 35.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Answer questions with short factoid answers.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:17:50,080] Trial 7 finished with value: 35.0 and parameters: {'0_predictor_instruction': 0, '0_predictor_demos': 0}. Best is trial 5 with value: 50.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of both works. \"Who Put the Bomp\" was published in 1996, while \"Self\" was published in 2000. Therefore, \"Self\" is the more recent publication.  \n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m compare the publication dates of both works. \"Who Put the Bomp\" was published in 1996, while \"Self\" was published in 2000. Therefore, \"Self\" is the more recent publication.  \n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 35.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Propose a detailed instruction that prompts the Language Model to analyze and reason through trivia questions by first identifying the key figures and events involved, then providing the necessary information to derive an accurate answer, while emphasizing the importance of comparing relevant facts to reach a conclusion.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-21 19:18:34,651] Trial 8 finished with value: 40.0 and parameters: {'0_predictor_instruction': 3, '0_predictor_demos': 1}. Best is trial 5 with value: 50.0.\n",
      "[I 2024-07-21 19:18:34,664] Trial 9 finished with value: 40.0 and parameters: {'0_predictor_instruction': 4, '0_predictor_demos': 3}. Best is trial 5 with value: 50.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Propose a detailed instruction that prompts the Language Model to analyze and reason through trivia questions by first identifying the key figures and events involved, then providing the necessary information to derive an accurate answer, while emphasizing the importance of comparing relevant facts to reach a conclusion.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine which publication was released last. We need to identify the release dates of both \"Who Put the Bomp\" and \"Self.\" \"Who Put the Bomp\" is a book by Greg Shaw that was published in 1996, while \"Self\" is a magazine that has had various issues over the years. By comparing the publication dates, we can conclude which one is more recent.\n",
      "Answer:\u001b[32m Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Propose a detailed instruction that prompts the Language Model to analyze and reason through trivia questions by first identifying the key figures and events involved, then providing the necessary information to derive an accurate answer, while emphasizing the importance of comparing relevant facts to reach a conclusion.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine which publication was released last. We need to identify the release dates of both \"Who Put the Bomp\" and \"Self.\" \"Who Put the Bomp\" is a book by Greg Shaw that was published in 1996, while \"Self\" is a magazine that has had various issues over the years. By comparing the publication dates, we can conclude which one is more recent.\n",
      "Answer:\u001b[32m Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 40.0\n",
      "CANDIDATE PROGRAM:\n",
      "Predictor 0\n",
      "i: Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "...\n",
      "FULL TRACE\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the publication years of each work. \"Who Put the Bomp\" was published in 1990, while \"Self\" was published in 1991. Therefore, \"Self\" is the more recent publication.\n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Compare and contrast the heights of two given structures or objects by step-by-step reasoning. Begin by identifying the heights of each structure, then evaluate which one is taller, and provide a concise answer indicating the taller structure. Include specific numerical data to support your reasoning.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their birth years. Aleksandr Danilovich Aleksandrov was born in 1937, while Anatoly Fomenko was born in 1945. Therefore, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the publication years of each work. \"Who Put the Bomp\" was published in 1990, while \"Self\" was published in 1991. Therefore, \"Self\" is the more recent publication.\n",
      "Answer: Self\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "Score 40.0\n"
     ]
    }
   ],
   "source": [
    "cot_fewshot_mipro = mipro_teleprompter.compile(generate_answer_with_chain_of_thought, trainset=trainset, \n",
    "                                               valset=devset,num_batches=10, max_bootstrapped_demos=1,\n",
    "                                               max_labeled_demos=2,requires_permission_to_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_dev_score = evaluate(cot_fewshot_mipro, devset=devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n",
      "[('self', Predict(StringSignature(question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")))]\n",
      "[('self', Predict(StringSignature(question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")))]\n"
     ]
    }
   ],
   "source": [
    "print(compiled_dev_score)\n",
    "cot_fewshot_mipro.save(\"cot_fewshot_mipro.dspy\")\n",
    "cot_fewshot.save(\"cot_fewshot.dspy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5] V3 Adding RAG\n",
    "\n",
    "To improve accuracy, we'll build a retrieval-augmented pipeline for answer generation.\n",
    "\n",
    "Given a question, we'll search for the top-3 passages in Wikipedia and then feed them as context for answer generation.\n",
    "\n",
    "Let's start by defining this signature: `context, question --> answer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the Retrieval Model\n",
    "\n",
    "Using the retriever is pretty simple. A module `dspy.Retrieve(k)` will search for the top-`k` passages that match a given query.\n",
    "\n",
    "Let's add our retriever with embeddings, hosted on a stanford domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 passages for question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible? \n",
      " ------------------------------ \n",
      "\n",
      "1] Restaurant: Impossible | Restaurant: Impossible is an American reality television series, featuring chef and restaurateur Robert Irvine, that aired on Food Network from 2011 to 2016. \n",
      "\n",
      "2] Jean Joho | Jean Joho is a French-American chef and restaurateur. He is chef/proprietor of Everest in Chicago (founded in 1986), Paris Club Bistro & Bar and Studio Paris in Chicago, The Eiffel Tower Restaurant in Las Vegas, and Brasserie JO in Boston. \n",
      "\n",
      "3] List of Restaurant: Impossible episodes | This is the list of the episodes for the American cooking and reality television series \"Restaurant Impossible\", produced by Food Network. The premise of the series is that within two days and on a budget of $10,000, celebrity chef Robert Irvine renovates a failing American restaurant with the goal of helping to restore it to profitability and prominence. Irvine is assisted by a designer (usually Taniya Nayak, Cheryl Torrenueva, or Lynn Keagan, but sometimes Vanessa De Leon, Krista Watterworth, Yvette Irene, or Nicole Faccuito), along with general contractor Tom Bury, who sometimes does double duty as both general contractor and designer. After assessing the problems with the restaurant, Robert Irvine typically creates a plan for the new decor, oversees the cleaning of the restaurant, reduces the size of the menu and improves the food, develops a promotional activity, educates the restaurant's owners, or trains the staff, as needed by each restaurant. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "dspy.settings.configure(lm=task_model, rm=colbertv2_wiki17_abstracts)\n",
    "retrieve = dspy.Retrieve(k=3)\n",
    "topK_passages = retrieve(dev_example.question).passages\n",
    "\n",
    "print(f\"Top {retrieve.k} passages for question: {dev_example.question} \\n\", '-' * 30, '\\n')\n",
    "\n",
    "for idx, passage in enumerate(topK_passages):\n",
    "    print(f'{idx+1}]', passage, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the RAG program. This is a class that inherits from `dspy.Module`.\n",
    "\n",
    "It needs two methods:\n",
    "\n",
    "- The `__init__` method will simply declare the sub-modules it needs: `dspy.Retrieve` and `dspy.ChainOfThought`. The latter is defined to implement our `GenerateAnswer` signature.\n",
    "- The `forward` method will describe the control flow of answering the question using the modules we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling the RAG program\n",
    "\n",
    "Having defined this program, let's now **compile** it. We'll define a new metric for checking both the retriever answers and generated answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:18<00:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've compiled our RAG program, let's try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. How about we inspect the last prompt for the LM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: \"Everything Has Changed\" is a song from an album released under which record label ?\n",
      "Answer: Big Machine Records\n",
      "\n",
      "Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\n",
      "Answer: 1950\n",
      "\n",
      "Question: Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?\n",
      "Answer: Aleem Sarwar Dar\n",
      "\n",
      "Question: Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers?\n",
      "Answer: \"Outfield of Dreams\"\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "Question: The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?\n",
      "Answer: 2010\n",
      "\n",
      "Question: Tombstone stared an actor born May 17, 1955 known as who?\n",
      "Answer: Bill Paxton\n",
      "\n",
      "Question: In what year was the club founded that played Manchester City in the 1972 FA Charity Shield\n",
      "Answer: 1874\n",
      "\n",
      "Question: which American actor was Candace Kita guest starred with\n",
      "Answer: Bill Murray\n",
      "\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Answer: The Empire State Building\n",
      "\n",
      "Question: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?\n",
      "Answer: Buena Vista Distribution\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.»\n",
      "[2] «Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.»\n",
      "[3] «Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine's Hall of Fame and \"Tae Kwon Do Times\" magazine's Hall of Fame.»\n",
      "\n",
      "Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We know from the context that \"Tae Kwon Do Times\" is a magazine that covers taekwondo and other Korean martial arts. It has published articles by authors like Scott Shaw. On the other hand, there is no information about Southwest Art magazine in the context.\n",
      "\n",
      "Answer: Tae Kwon Do Times\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.»\n",
      "[2] «Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That's Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.»\n",
      "[3] «Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.»\n",
      "\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We know that the actress made her film debut in 1995 and co-founded Voto Latino.\n",
      "\n",
      "Answer: Rosario Dawson\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.»\n",
      "[2] «Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.»\n",
      "[3] «Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.»\n",
      "\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We know that the German offensive that started the Battle of Kursk was called Operation Citadel.\n",
      "\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC's \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"»\n",
      "[2] «Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly's Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.»\n",
      "[3] «Judi Dench | Dame Judith Olivia \"Judi\" Dench, {'1': \", '2': \", '3': \", '4': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare's plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.»\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We know that the actress we are looking for is the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" We also know that she acted in the short film The Shore.\n",
      "\n",
      "Answer: Kerry Condon\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»\n",
      "[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»\n",
      "[3] «David Gregory (mathematician) | David Gregory (originally spelt Gregorie) FRS (? 1659 – 10 October 1708) was a Scottish mathematician and astronomer. He was professor of mathematics at the University of Edinburgh, Savilian Professor of Astronomy at the University of Oxford, and a commentator on Isaac Newton's \"Principia\".»\n",
      "\n",
      "Question: What castle did David Gregory inherit?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know that David Gregory inherited a castle. The name of the castle is Kinnairdy Castle.\n",
      "\n",
      "Answer: Kinnairdy Castle\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we haven't written any of this detailed demonstrations, we see that **DSPy** was able to bootstrap this 3,000 token prompt for **3-shot retrieval augmented generation with hard negative passages and chain of thought** from our extremely simple program.\n",
    "\n",
    "This illustrates the power of composition and learning. Of course, this was just generated by a particular teleprompter, which may or may not be perfect in each setting. As you'll see in **DSPy**, there is a large but systematic space of options you have to optimize and validate the quality and cost of your programs.\n",
    "\n",
    "If you're so inclined, you can easily inspect the learned objects themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_answer\n",
      "Example({'augmented': True, 'context': ['Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.', 'Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.', 'Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.'], 'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'rationale': 'identify the German offensive that initiated the Battle of Kursk. The context mentions that the German offensive was called Operation Citadel, which began on 5 July 1943.', 'answer': 'Operation Citadel'}) (input_keys=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in compiled_rag.named_predictors():\n",
    "    print(name)\n",
    "    print(parameter.demos[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the Answers\n",
    "\n",
    "We can now evaluate our `compiled_rag` program on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate(compiled_rag, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('self', Predict(StringSignature(question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")))]\n"
     ]
    }
   ],
   "source": [
    "cot_fewshot.save(\"compiled_rag.dspy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
